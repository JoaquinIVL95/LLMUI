# Gu√≠a de Optimizaci√≥n del CLI

## Problema del "Thinking" en Qwen3

El modelo **qwen3:8b** incluye un mecanismo de "thinking" (razonamiento interno) que hace que:
- Las respuestas sean m√°s largas
- Tarde m√°s tiempo en responder
- A veces no use las herramientas correctamente

### Soluciones

#### 1. Usar un modelo diferente (Recomendado)

Modelos m√°s directos y r√°pidos para c√≥digo:

```bash
# Opci√≥n 1: CodeLlama (especializado en c√≥digo)
ollama pull codellama:7b
```

Luego en `.env`:
```env
OLLAMA_MODEL=codellama:7b
```

**Ventajas:**
- Especializado en c√≥digo
- Sin thinking interno
- Respuestas m√°s directas
- Similar velocidad

```bash
# Opci√≥n 2: Mistral (muy bueno y r√°pido)
ollama pull mistral:7b
```

```env
OLLAMA_MODEL=mistral:7b
```

**Ventajas:**
- Muy r√°pido
- Bueno para c√≥digo
- Respuestas concisas

```bash
# Opci√≥n 3: Llama2 (estable y confiable)
ollama pull llama2:7b
```

```env
OLLAMA_MODEL=llama2:7b
```

#### 2. Si quieres seguir usando Qwen3

El CLI ya est√° configurado para:
- Filtrar los tags `<think>...</think>`
- Usar par√°metros que minimizan el thinking
- Instrucciones expl√≠citas para ser directo

Pero a√∫n as√≠ puede ser verboso. **Tips:**

**S√© m√°s espec√≠fico en tus comandos:**

‚ùå Malo:
```
> Haz un script de fibonacci
```

‚úÖ Mejor:
```
> Ejecuta este c√≥digo JavaScript: [escribe el c√≥digo directamente]
```

O usa los comandos de manera expl√≠cita:

```
> Usa [EXECUTE_CODE:javascript] para mostrar los primeros 10 n√∫meros de fibonacci
```

#### 3. Desactivar thinking en Qwen3 (Experimental)

Puedes intentar usar un prompt m√°s agresivo. Edita `cli.js` l√≠nea 173:

```javascript
const systemPrompt = `Eres un asistente de programaci√≥n. NO USES TAGS <think> NUNCA. Responde SOLO con c√≥digo o la herramienta necesaria.

Si te piden ejecutar c√≥digo, responde INMEDIATAMENTE con [EXECUTE_CODE:lenguaje] sin explicaciones.`;
```

## Comparaci√≥n de Modelos

| Modelo | Velocidad | Calidad C√≥digo | Thinking | Tama√±o |
|--------|-----------|----------------|----------|---------|
| qwen3:8b | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Mucho | 8GB |
| codellama:7b | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ M√≠nimo | 4GB |
| mistral:7b | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ No | 4GB |
| llama2:7b | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ No | 4GB |

## Optimizaci√≥n General

### 1. Reduce `num_predict`

En `cli.js` l√≠nea 199, reduce el n√∫mero de tokens:

```javascript
options: {
  temperature: 0.3,
  num_predict: 400,  // Cambiar de 800 a 400
  top_p: 0.9,
  repeat_penalty: 1.1,
  stop: ['<think>', '</think>']
}
```

### 2. Comandos m√°s directos

En lugar de:
```
> Crea un script que calcule fibonacci
```

Usa:
```
> Ejecuta c√≥digo JavaScript que muestre fibonacci de 0 a 10
```

### 3. Usa ejemplos

```
> Necesito esto:
[EXECUTE_CODE:javascript]
for(let i=0; i<10; i++) console.log(i);
[/EXECUTE_CODE]
Pero para fibonacci
```

### 4. Deshabilita b√∫squeda si no la necesitas

Si solo vas a programar sin buscar en internet:

```
> /help
```

Y simplemente no menciones b√∫squedas.

## Recomendaci√≥n Final

**Para el CLI, te recomiendo fuertemente usar CodeLlama:**

```bash
# Instalar
ollama pull codellama:7b

# Configurar en .env
OLLAMA_MODEL=codellama:7b

# Reiniciar CLI
npm run cli
```

**Razones:**
1. Especializado en c√≥digo
2. Mucho m√°s r√°pido que qwen3
3. Sin thinking interno
4. Entiende mejor las herramientas de c√≥digo
5. Respuestas m√°s concisas

## Ejemplo Comparativo

### Con Qwen3:8b
```
> Fibonacci en JavaScript

ü§ñ Asistente:
<think>
Okay, el usuario quiere fibonacci... [500 palabras de razonamiento]
</think>

Claro, aqu√≠ est√° el c√≥digo:
[EXECUTE_CODE:javascript]
...
[/EXECUTE_CODE]

[Explicaci√≥n de 200 palabras m√°s]
```
‚è±Ô∏è Tiempo: ~15-20 segundos

### Con CodeLlama:7b
```
> Fibonacci en JavaScript

ü§ñ Asistente:
[EXECUTE_CODE:javascript]
let a=0,b=1;
console.log(a,b);
for(let i=2;i<10;i++){
  let c=a+b;
  console.log(c);
  a=b;b=c;
}
[/EXECUTE_CODE]
```
‚è±Ô∏è Tiempo: ~3-5 segundos

## Verificar cambios

Despu√©s de cambiar el modelo:

```bash
# Verificar que Ollama tiene el modelo
ollama list

# Deber√≠a aparecer tu nuevo modelo

# Reiniciar el CLI
npm run cli

# Probar
> Hola
```

Deber√≠as ver respuestas mucho m√°s r√°pidas y directas.
